{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISID：Azureを用いたAutomated MLと機械学習モデルの説明性・解釈性のデモ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事前準備\n",
    "\n",
    "Azure ML VMを使用。作成したVMにSSHで接続し、JupyterNotebookを設定します。\n",
    "TeraTermなどを使用します。\n",
    "\n",
    "conda info -e\n",
    "\n",
    "でどのような仮想環境が存在するか確認し、py36に入ります。\n",
    "\n",
    "source activate py36\n",
    "\n",
    "jupyter notebookのpasswordを設定します。\n",
    "\n",
    "jupyter notebook password\n",
    "\n",
    "jupyter notebook を立ち上げます。\n",
    "\n",
    "jupyter notebook\n",
    "\n",
    "TeraTermのssh転送の8888を許可します\n",
    "\n",
    "表示されるURLにアクセスします。\n",
    "http://localhost:8888/tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 実行環境の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing /data/anaconda/envs/py36/lib/python3.6/site-packages/azureml/contrib/explain/model/visualize/static -> microsoft-mli-widget\n",
      "Up to date: /data/anaconda/envs/py36/share/jupyter/nbextensions/microsoft-mli-widget/index.js.map\n",
      "Up to date: /data/anaconda/envs/py36/share/jupyter/nbextensions/microsoft-mli-widget/index.js\n",
      "Up to date: /data/anaconda/envs/py36/share/jupyter/nbextensions/microsoft-mli-widget/extension.js.map\n",
      "Up to date: /data/anaconda/envs/py36/share/jupyter/nbextensions/microsoft-mli-widget/extension.js\n",
      "- Validating: \u001b[32mOK\u001b[0m\n",
      "\n",
      "    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n",
      "    \n",
      "          jupyter nbextension enable azureml.contrib.explain.model.visualize --py --sys-prefix\n",
      "    \n",
      "Enabling notebook extension microsoft-mli-widget/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 最初に描画の設定をONにする\n",
    "!jupyter nbextension install --py --sys-prefix azureml.contrib.explain.model.visualize\n",
    "!jupyter nbextension enable --py --sys-prefix azureml.contrib.explain.model.visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行上問題ないwarningは非表示にする\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数シードの固定\n",
    "seed_value= 1234  # Seedの適当な値\n",
    "\n",
    "# 1. pythonのシード固定\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    " \n",
    "# 2. randomのシード固定\n",
    "import random\n",
    "random.seed(seed_value)\n",
    " \n",
    "# 3. Numpyのシード固定\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0816 09:15:06.605536 139822054012672 deprecation_wrapper.py:119] From /data/anaconda/envs/py36/lib/python3.6/site-packages/azureml/automl/core/_vendor/automl/client/core/common/tf_wrappers.py:36: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0816 09:15:06.606585 139822054012672 deprecation_wrapper.py:119] From /data/anaconda/envs/py36/lib/python3.6/site-packages/azureml/automl/core/_vendor/automl/client/core/common/tf_wrappers.py:36: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# パッケージのimport\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# Azure関連\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "import logging\n",
    "from azureml.train.automl import AutoMLConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. タイタニック・データのロードと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# タイタニックデータ取得\n",
    "# 参考\n",
    "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/explain-model/tabular-data/advanced-feature-transformations-explain-local.ipynb\n",
    "\n",
    "titanic_url = ('https://raw.githubusercontent.com/amueller/'\n",
    "               'scipy-2017-sklearn/091d371/notebooks/datasets/titanic3.csv')\n",
    "data = pd.read_csv(titanic_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを作成\n",
    "target_feature = ['survived']\n",
    "numeric_features = ['age', 'fare','sibsp','parch']\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "\n",
    "df = data[target_feature+categorical_features + numeric_features]\n",
    "y = data[target_feature].values\n",
    "X = data[categorical_features + numeric_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. タイタニックデータについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>embarked</th>\n",
       "      <th>sex</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>29.00</td>\n",
       "      <td>211.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>151.55</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>151.55</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>30.00</td>\n",
       "      <td>151.55</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>25.00</td>\n",
       "      <td>151.55</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived embarked     sex  pclass   age   fare  sibsp  parch\n",
       "0         1        S  female       1 29.00 211.34      0      0\n",
       "1         1        S    male       1  0.92 151.55      1      2\n",
       "2         0        S  female       1  2.00 151.55      1      2\n",
       "3         0        S    male       1 30.00 151.55      1      2\n",
       "4         0        S  female       1 25.00 151.55      1      2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Survived：目的変数（生存者は1）\n",
    "\n",
    "- embarked：乗船した港　Cherbourg（シェルブール）、Queenstown、Southampton（サウサンプトン）の３種類\n",
    "- sex：男性・女性\n",
    "- pclass：乗客チケットの階級（1が一番が高い）\n",
    "- age：年齢\n",
    "- fare：乗船料金\n",
    "- sibsp：兄弟、配偶者の同船者数\n",
    "- parch：両親、子供の同船者数\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked     object\n",
       "sex          object\n",
       "pclass        int64\n",
       "age         float64\n",
       "fare        float64\n",
       "sibsp         int64\n",
       "parch         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの型を確認\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked     object\n",
       "sex          object\n",
       "pclass       object\n",
       "age         float64\n",
       "fare        float64\n",
       "sibsp         int64\n",
       "parch         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pclassの型を修正\n",
    "X[\"pclass\"] = X[\"pclass\"].astype(str)\n",
    "X.dtypes\n",
    "\n",
    "# ageは後でintに直す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked     True\n",
       "sex         False\n",
       "pclass      False\n",
       "age          True\n",
       "fare         True\n",
       "sibsp       False\n",
       "parch       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欠損値のある列を確認\n",
    "X.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked    False\n",
       "sex         False\n",
       "pclass      False\n",
       "age          True\n",
       "fare         True\n",
       "sibsp       False\n",
       "parch       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embarkedの欠損値を修正\n",
    "X['embarked'] = X['embarked'].fillna(\"missing\")\n",
    "X.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ageとfareの欠損値を修正\n",
    "# データを分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 訓練データで中央値を求める\n",
    "age_median = x_train[\"age\"].median()\n",
    "fare_median = x_train[\"fare\"].median()\n",
    "\n",
    "X[\"age\"] = X[\"age\"].fillna(age_median)\n",
    "X[\"fare\"] = X[\"fare\"].fillna(fare_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked    False\n",
       "sex         False\n",
       "pclass      False\n",
       "age         False\n",
       "fare        False\n",
       "sibsp       False\n",
       "parch       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked     object\n",
       "sex          object\n",
       "pclass       object\n",
       "age           int64\n",
       "fare        float64\n",
       "sibsp         int64\n",
       "parch         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ageの型修正\n",
    "X[\"age\"] = X[\"age\"].astype(np.int64)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 機械学習用の前処理モデルとデータを用意する\n",
    "\n",
    "## 4.1 前処理パイプラインを設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "transformations = ColumnTransformer([\n",
    "    (\"categorical\",  Pipeline(steps=[\n",
    "        ('encoder', OneHotEncoder(sparse=False))]), categorical_features),\n",
    "    (\"numeric\",  Pipeline(steps=[\n",
    "        ('scaler', PolynomialFeatures(1))]), numeric_features),  # 実質何もしない\n",
    "])\n",
    "\n",
    "# 欠損値処理を、前処理パイプラインにimputerで組み込むことも考えられるが、\n",
    "# データの型を修正するのに、欠損値処理が必要なので、\n",
    "# 欠損値は先に処理しておく\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('categorical', Pipeline(memory=None,\n",
       "     steps=[('encoder', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=False))]), ['embarked', 'sex', 'pclass']), ('numeric', Pipeline(memory=None,\n",
       "     steps=[('scaler', PolynomialFeatures(degree=1, include_bias=True, interaction_only=False))]), ['age', 'fare', 'sibsp', 'parch'])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 前処理の実施\n",
    "transformations.fit(X)\n",
    "\n",
    "# Xに対して前処理を学習させているが、今回は前処理がone-hot EncodingのみなのでOK\n",
    "# 数値データの平均値での処理などは、訓練データとテストデータを分けてから訓練データに適用すべきなので、\n",
    "# その際は注意すること\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 データを訓練とテストに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理の実施\n",
    "x_train_transformed = transformations.transform(x_train)\n",
    "x_test_transformed = transformations.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1047, 14)\n",
      "[[  0.      0.      1.      0.      0.      1.      0.      0.      1.\n",
      "    1.     25.      7.925   0.      0.   ]\n",
      " [  1.      0.      0.      0.      1.      0.      1.      0.      0.\n",
      "    1.     41.    134.5     0.      0.   ]]\n"
     ]
    }
   ],
   "source": [
    "# 前処理後のデータを確認\n",
    "print(x_train_transformed.shape)\n",
    "print(x_train_transformed[0:2,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_C', 'x0_Q', 'x0_S', 'x0_missing', 'x1_female', 'x1_male',\n",
       "       'x2_1', 'x2_2', 'x2_3'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 列名を確認\n",
    "transformations.named_transformers_[\"categorical\"].steps[0][1].get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 目的変数に対する処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yを無次元のnumpyに\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Automated MLの実施"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Azure MLサービスのワークスペース（WS）に接続し、実験を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワークスペースに接続\n",
    "ws = Workspace.from_config(path='./ws_config.json')\n",
    "\n",
    "# 実験を作成\n",
    "experiment_name = 'automl-classification6'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "# 実行したら、表示される\n",
    "#  open the page https://microsoft.com/devicelogin and enter the code ＜・・・＞ to authenticate.\n",
    "# のコード＜・・・＞を、https://microsoft.com/devicelogin で入力する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Automated MLをローカル環境で実行する設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_run = experiment.submit(automl_config, show_output = True)\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             verbosity=logging.INFO,\n",
    "                             primary_metric = 'accuracy',\n",
    "                             X = x_train_transformed, \n",
    "                             y = y_train,\n",
    "                             n_cross_validations = 8,\n",
    "                             enable_voting_ensemble=True,\n",
    "                             enable_stack_ensemble=True,\n",
    "                             iterations = 50,\n",
    "                            )\n",
    "\n",
    "\n",
    "# primary_metricで選べる情報\n",
    "# https://docs.microsoft.com/ja-jp/azure/machine-learning/service/how-to-understand-automated-ml#classification-metrics\n",
    "# その他、設定情報\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.automlconfig?view=azure-ml-py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Automated MLをクラウド環境で実行する場合の設定\n",
    "\n",
    "現在、コメントアウトしています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom azureml.core.compute import AmlCompute\\nfrom azureml.core.compute import ComputeTarget\\n\\n# コンピューティング・クラスターの名前\\namlcompute_cluster_name = \"automlcl\"  \\n\\nprovisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\\n                                                            # for GPU, use \"STANDARD_NC6\"\\n                                                            # vm_priority = \\'lowpriority\\', # optional\\n                                                            max_nodes=2)\\n# VMたちを作成\\ncompute_target = ComputeTarget.create(\\n    ws, amlcompute_cluster_name, provisioning_config)\\n\\ncompute_target.wait_for_completion(\\n    show_output=True, min_node_count=None, timeout_in_minutes=20)\\n\\n# -----------------------------------\\n# リモートVMの設定を与える\\n# -----------------------------------\\nfrom azureml.core.runconfig import RunConfiguration\\nfrom azureml.core.conda_dependencies import CondaDependencies\\nimport pkg_resources\\n\\n# RunConfigの設定\\nconda_run_config = RunConfiguration(framework=\"python\")\\n\\n# 作成したcompute_targetを指定\\nconda_run_config.target = compute_target\\n\\n# その他、設定\\nconda_run_config.environment.docker.enabled = True\\nconda_run_config.environment.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE\\ndprep_dependency = \\'azureml-dataprep==\\' + pkg_resources.get_distribution(\"azureml-dataprep\").version\\ncd = CondaDependencies.create(pip_packages=[\\'azureml-sdk[automl]\\', dprep_dependency], conda_packages=[\\'numpy\\',\\'py-xgboost<=0.80\\'])\\nconda_run_config.environment.python.conda_dependencies = c\\n\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# コンピューティング・クラスターの名前\n",
    "amlcompute_cluster_name = \"automlcl\"  \n",
    "\n",
    "provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                            # for GPU, use \"STANDARD_NC6\"\n",
    "                                                            # vm_priority = 'lowpriority', # optional\n",
    "                                                            max_nodes=2)\n",
    "# VMたちを作成\n",
    "compute_target = ComputeTarget.create(\n",
    "    ws, amlcompute_cluster_name, provisioning_config)\n",
    "\n",
    "compute_target.wait_for_completion(\n",
    "    show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# -----------------------------------\n",
    "# リモートVMの設定を与える\n",
    "# -----------------------------------\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "import pkg_resources\n",
    "\n",
    "# RunConfigの設定\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# 作成したcompute_targetを指定\n",
    "conda_run_config.target = compute_target\n",
    "\n",
    "# その他、設定\n",
    "conda_run_config.environment.docker.enabled = True\n",
    "conda_run_config.environment.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE\n",
    "dprep_dependency = 'azureml-dataprep==' + pkg_resources.get_distribution(\"azureml-dataprep\").version\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-sdk[automl]', dprep_dependency], conda_packages=['numpy','py-xgboost<=0.80'])\n",
    "conda_run_config.environment.python.conda_dependencies = c\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nautoml_config = AutoMLConfig(task = 'classification',\\n                             verbosity=logging.INFO,\\n                             primary_metric = 'accuracy',\\n                             X = x_train_transformed, \\n                             y = y_train,\\n                             n_cross_validations = 10,\\n                             enable_voting_ensemble=True,\\n                             enable_stack_ensemble=True,\\n                             iterations = 30,\\n                             enable_early_stopping=False,\\n                             run_configuration=conda_run_config  # 追加されている \\n                            )\\n\\n# 詳細\\n# https://docs.microsoft.com/ja-jp/azure/machine-learning/service/how-to-auto-train-remote\\n# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/automated-machine-learning/remote-amlcompute/auto-ml-remote-amlcompute.ipynb\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             verbosity=logging.INFO,\n",
    "                             primary_metric = 'accuracy',\n",
    "                             X = x_train_transformed, \n",
    "                             y = y_train,\n",
    "                             n_cross_validations = 10,\n",
    "                             enable_voting_ensemble=True,\n",
    "                             enable_stack_ensemble=True,\n",
    "                             iterations = 30,\n",
    "                             enable_early_stopping=False,\n",
    "                             run_configuration=conda_run_config  # 追加されている \n",
    "                            )\n",
    "\n",
    "# 詳細\n",
    "# https://docs.microsoft.com/ja-jp/azure/machine-learning/service/how-to-auto-train-remote\n",
    "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/automated-machine-learning/remote-amlcompute/auto-ml-remote-amlcompute.ipynb\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Automated MLの開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_30ebc59a-9a4e-47ce-bdf3-be045c67572e\n",
      "Current status: DatasetCrossValidationSplit. Generating CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   StandardScalerWrapper SGD                      0:00:22       0.7851    0.7851\n",
      "         1   StandardScalerWrapper SGD                      0:00:08       0.7689    0.7851\n",
      "         2   MinMaxScaler SGD                               0:00:08       0.7803    0.7851\n",
      "         3   MinMaxScaler RandomForest                      0:00:08       0.7841    0.7851\n",
      "         4   StandardScalerWrapper RandomForest             0:00:08       0.7698    0.7851\n",
      "         5   StandardScalerWrapper SGD                      0:00:08       0.7765    0.7851\n",
      "         6   StandardScalerWrapper ExtremeRandomTrees       0:00:10       0.8023    0.8023\n",
      "         7   MinMaxScaler RandomForest                      0:00:10       0.7688    0.8023\n",
      "         8   StandardScalerWrapper BernoulliNaiveBayes      0:00:08       0.7650    0.8023\n",
      "         9   MinMaxScaler ExtremeRandomTrees                0:00:08       0.7880    0.8023\n",
      "        10   MaxAbsScaler SVM                               0:00:19       0.8004    0.8023\n",
      "        11   MaxAbsScaler LightGBM                          0:00:09       0.8090    0.8090\n",
      "        12   MinMaxScaler LightGBM                          0:00:09       0.7937    0.8090\n",
      "        13   TruncatedSVDWrapper KNN                        0:00:09       0.7010    0.8090\n",
      "        14   RobustScaler LightGBM                          0:00:10       0.8109    0.8109\n",
      "        15   StandardScalerWrapper LightGBM                 0:00:09       0.7861    0.8109\n",
      "        16   MinMaxScaler LightGBM                          0:00:09       0.7956    0.8109\n",
      "        17   MinMaxScaler SVM                               0:00:10       0.7803    0.8109\n",
      "        18   MaxAbsScaler LogisticRegression                0:00:08       0.7698    0.8109\n",
      "        19   StandardScalerWrapper LightGBM                 0:00:09       0.8042    0.8109\n",
      "        20   StandardScalerWrapper LightGBM                 0:00:09       0.6180    0.8109\n",
      "        21   MaxAbsScaler LightGBM                          0:00:11       0.8013    0.8109\n",
      "        22   MinMaxScaler LightGBM                          0:00:10       0.7908    0.8109\n",
      "        23   StandardScalerWrapper LightGBM                 0:00:09       0.7851    0.8109\n",
      "        24   MaxAbsScaler LightGBM                          0:00:09       0.7908    0.8109\n",
      "        25   StandardScalerWrapper LightGBM                 0:00:09       0.7803    0.8109\n",
      "        26   StandardScalerWrapper LogisticRegression       0:00:09       0.7698    0.8109\n",
      "        27   MaxAbsScaler GradientBoosting                  0:00:13       0.7908    0.8109\n",
      "        28   StandardScalerWrapper LightGBM                 0:00:09       0.8013    0.8109\n",
      "        29   StandardScalerWrapper GradientBoosting         0:00:16       0.7994    0.8109\n",
      "        30   StandardScalerWrapper LightGBM                 0:00:10       0.8090    0.8109\n",
      "        31   StandardScalerWrapper LogisticRegression       0:00:09       0.7879    0.8109\n",
      "        32   StandardScalerWrapper LightGBM                 0:00:09       0.7746    0.8109\n",
      "        33   MaxAbsScaler LogisticRegression                0:00:09       0.7707    0.8109\n",
      "        34   StandardScalerWrapper LightGBM                 0:00:09       0.8023    0.8109\n",
      "        35   StandardScalerWrapper LightGBM                 0:00:13       0.7851    0.8109\n",
      "        36   RobustScaler LightGBM                          0:00:09       0.7909    0.8109\n",
      "        37   MinMaxScaler LightGBM                          0:00:11       0.7995    0.8109\n",
      "        38   StandardScalerWrapper SGD                      0:00:09       0.7698    0.8109\n",
      "        39   StandardScalerWrapper LightGBM                 0:00:11       0.8071    0.8109\n",
      "        40   TruncatedSVDWrapper LightGBM                   0:00:10       0.6686    0.8109\n",
      "        41   StandardScalerWrapper LightGBM                 0:00:10       0.8118    0.8118\n",
      "        42   RobustScaler LightGBM                          0:00:11       0.7985    0.8118\n",
      "        43   SparseNormalizer RandomForest                  0:00:10       0.7679    0.8118\n",
      "        44   StandardScalerWrapper LightGBM                 0:00:09       0.7966    0.8118\n",
      "        45   MaxAbsScaler LightGBM                          0:00:09       0.7947    0.8118\n",
      "        46   StandardScalerWrapper LogisticRegression       0:00:09       0.7899    0.8118\n",
      "        47   SparseNormalizer LightGBM                      0:00:10       0.7956    0.8118\n",
      "        48   VotingEnsemble                                 0:00:20       0.8176    0.8176\n",
      "        49   StackEnsemble                                  0:00:20       0.8109    0.8176\n"
     ]
    }
   ],
   "source": [
    "my_run = experiment.submit(automl_config, show_output = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Automated MLの実行結果を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4070daa440a4daf85eb85444a0481a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(my_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automl-classification6,\n",
      "Id: AutoML_30ebc59a-9a4e-47ce-bdf3-be045c67572e_48,\n",
      "Type: None,\n",
      "Status: Completed)\n"
     ]
    }
   ],
   "source": [
    "# 最高性能のモデルを取得\n",
    "best_run, fitted_model = my_run.get_output()\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefittedsoftvotingclassifier\n",
      "{'estimators': ['41', '14', '30', '11', '39', '34', '28'],\n",
      " 'weights': [0.13333333333333333,\n",
      "             0.2,\n",
      "             0.13333333333333333,\n",
      "             0.06666666666666667,\n",
      "             0.26666666666666666,\n",
      "             0.13333333333333333,\n",
      "             0.06666666666666667]}\n",
      "\n",
      "41 - StandardScalerWrapper\n",
      "{'class_name': 'StandardScaler',\n",
      " 'copy': True,\n",
      " 'module_name': 'sklearn.preprocessing.data',\n",
      " 'with_mean': True,\n",
      " 'with_std': False}\n",
      "\n",
      "41 - LightGBMClassifier\n",
      "{'boosting_type': 'gbdt',\n",
      " 'class_weight': None,\n",
      " 'colsample_bytree': 0.6933333333333332,\n",
      " 'importance_type': 'split',\n",
      " 'learning_rate': 0.036848421052631586,\n",
      " 'max_bin': 130,\n",
      " 'max_depth': 3,\n",
      " 'min_child_samples': 19,\n",
      " 'min_child_weight': 10,\n",
      " 'min_split_gain': 0.10526315789473684,\n",
      " 'n_estimators': 800,\n",
      " 'n_jobs': 1,\n",
      " 'num_leaves': 8,\n",
      " 'objective': None,\n",
      " 'random_state': None,\n",
      " 'reg_alpha': 0.9473684210526315,\n",
      " 'reg_lambda': 0.3684210526315789,\n",
      " 'silent': True,\n",
      " 'subsample': 0.49526315789473685,\n",
      " 'subsample_for_bin': 200000,\n",
      " 'subsample_freq': 0,\n",
      " 'verbose': -10}\n",
      "\n",
      "14 - RobustScaler\n",
      "{'copy': True,\n",
      " 'quantile_range': [25, 75],\n",
      " 'with_centering': True,\n",
      " 'with_scaling': True}\n",
      "\n",
      "14 - LightGBMClassifier\n",
      "{'boosting_type': 'gbdt',\n",
      " 'class_weight': None,\n",
      " 'colsample_bytree': 0.5944444444444444,\n",
      " 'importance_type': 'split',\n",
      " 'learning_rate': 0.07894947368421053,\n",
      " 'max_bin': 160,\n",
      " 'max_depth': 9,\n",
      " 'min_child_samples': 15,\n",
      " 'min_child_weight': 3,\n",
      " 'min_split_gain': 0.10526315789473684,\n",
      " 'n_estimators': 800,\n",
      " 'n_jobs': 1,\n",
      " 'num_leaves': 80,\n",
      " 'objective': None,\n",
      " 'random_state': None,\n",
      " 'reg_alpha': 0.6842105263157894,\n",
      " 'reg_lambda': 0.5789473684210527,\n",
      " 'silent': True,\n",
      " 'subsample': 0.99,\n",
      " 'subsample_for_bin': 200000,\n",
      " 'subsample_freq': 0,\n",
      " 'verbose': -10}\n",
      "\n",
      "30 - StandardScalerWrapper\n",
      "{'class_name': 'StandardScaler',\n",
      " 'copy': True,\n",
      " 'module_name': 'sklearn.preprocessing.data',\n",
      " 'with_mean': True,\n",
      " 'with_std': True}\n",
      "\n",
      "30 - LightGBMClassifier\n",
      "{'boosting_type': 'gbdt',\n",
      " 'class_weight': None,\n",
      " 'colsample_bytree': 0.3966666666666666,\n",
      " 'importance_type': 'split',\n",
      " 'learning_rate': 0.06316157894736842,\n",
      " 'max_bin': 280,\n",
      " 'max_depth': 5,\n",
      " 'min_child_samples': 15,\n",
      " 'min_child_weight': 9,\n",
      " 'min_split_gain': 0.3684210526315789,\n",
      " 'n_estimators': 800,\n",
      " 'n_jobs': 1,\n",
      " 'num_leaves': 227,\n",
      " 'objective': None,\n",
      " 'random_state': None,\n",
      " 'reg_alpha': 0.3684210526315789,\n",
      " 'reg_lambda': 0.8421052631578947,\n",
      " 'silent': True,\n",
      " 'subsample': 0.9405263157894738,\n",
      " 'subsample_for_bin': 200000,\n",
      " 'subsample_freq': 0,\n",
      " 'verbose': -10}\n",
      "\n",
      "11 - MaxAbsScaler\n",
      "{'copy': True}\n",
      "\n",
      "11 - LightGBMClassifier\n",
      "{'boosting_type': 'gbdt',\n",
      " 'class_weight': None,\n",
      " 'colsample_bytree': 0.3966666666666666,\n",
      " 'importance_type': 'split',\n",
      " 'learning_rate': 0.04211105263157895,\n",
      " 'max_bin': 70,\n",
      " 'max_depth': 8,\n",
      " 'min_child_samples': 22,\n",
      " 'min_child_weight': 9,\n",
      " 'min_split_gain': 0.2631578947368421,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': 1,\n",
      " 'num_leaves': 119,\n",
      " 'objective': None,\n",
      " 'random_state': None,\n",
      " 'reg_alpha': 0.894736842105263,\n",
      " 'reg_lambda': 0.6842105263157894,\n",
      " 'silent': True,\n",
      " 'subsample': 0.49526315789473685,\n",
      " 'subsample_for_bin': 200000,\n",
      " 'subsample_freq': 0,\n",
      " 'verbose': -10}\n",
      "\n",
      "39 - StandardScalerWrapper\n",
      "{'class_name': 'StandardScaler',\n",
      " 'copy': True,\n",
      " 'module_name': 'sklearn.preprocessing.data',\n",
      " 'with_mean': True,\n",
      " 'with_std': False}\n",
      "\n",
      "39 - LightGBMClassifier\n",
      "{'boosting_type': 'goss',\n",
      " 'class_weight': None,\n",
      " 'colsample_bytree': 0.7922222222222222,\n",
      " 'importance_type': 'split',\n",
      " 'learning_rate': 0.05789894736842106,\n",
      " 'max_bin': 300,\n",
      " 'max_depth': 3,\n",
      " 'min_child_samples': 29,\n",
      " 'min_child_weight': 0,\n",
      " 'min_split_gain': 0,\n",
      " 'n_estimators': 600,\n",
      " 'n_jobs': 1,\n",
      " 'num_leaves': 8,\n",
      " 'objective': None,\n",
      " 'random_state': None,\n",
      " 'reg_alpha': 0.10526315789473684,\n",
      " 'reg_lambda': 0.631578947368421,\n",
      " 'silent': True,\n",
      " 'subsample': 1,\n",
      " 'subsample_for_bin': 200000,\n",
      " 'subsample_freq': 0,\n",
      " 'verbose': -10}\n",
      "\n",
      "34 - StandardScalerWrapper\n",
      "{'class_name': 'StandardScaler',\n",
      " 'copy': True,\n",
      " 'module_name': 'sklearn.preprocessing.data',\n",
      " 'with_mean': True,\n",
      " 'with_std': False}\n",
      "\n",
      "34 - LightGBMClassifier\n",
      "{'boosting_type': 'gbdt',\n",
      " 'class_weight': None,\n",
      " 'colsample_bytree': 0.8911111111111111,\n",
      " 'importance_type': 'split',\n",
      " 'learning_rate': 0.05263631578947369,\n",
      " 'max_bin': 90,\n",
      " 'max_depth': -1,\n",
      " 'min_child_samples': 58,\n",
      " 'min_child_weight': 7,\n",
      " 'min_split_gain': 0.47368421052631576,\n",
      " 'n_estimators': 400,\n",
      " 'n_jobs': 1,\n",
      " 'num_leaves': 110,\n",
      " 'objective': None,\n",
      " 'random_state': None,\n",
      " 'reg_alpha': 0.7368421052631579,\n",
      " 'reg_lambda': 0.7368421052631579,\n",
      " 'silent': True,\n",
      " 'subsample': 0.8910526315789474,\n",
      " 'subsample_for_bin': 200000,\n",
      " 'subsample_freq': 0,\n",
      " 'verbose': -10}\n",
      "\n",
      "28 - StandardScalerWrapper\n",
      "{'class_name': 'StandardScaler',\n",
      " 'copy': True,\n",
      " 'module_name': 'sklearn.preprocessing.data',\n",
      " 'with_mean': True,\n",
      " 'with_std': False}\n",
      "\n",
      "28 - LightGBMClassifier\n",
      "{'boosting_type': 'goss',\n",
      " 'class_weight': None,\n",
      " 'colsample_bytree': 0.99,\n",
      " 'importance_type': 'split',\n",
      " 'learning_rate': 0.03158578947368421,\n",
      " 'max_bin': 310,\n",
      " 'max_depth': -1,\n",
      " 'min_child_samples': 4,\n",
      " 'min_child_weight': 5,\n",
      " 'min_split_gain': 0.05263157894736842,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': 1,\n",
      " 'num_leaves': 143,\n",
      " 'objective': None,\n",
      " 'random_state': None,\n",
      " 'reg_alpha': 0,\n",
      " 'reg_lambda': 0.47368421052631576,\n",
      " 'silent': True,\n",
      " 'subsample': 1,\n",
      " 'subsample_for_bin': 200000,\n",
      " 'subsample_freq': 0,\n",
      " 'verbose': -10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 最高性能のモデルの詳細\n",
    "from pprint import pprint\n",
    "\n",
    "def print_model(model, prefix=\"\"):\n",
    "    for step in model.steps:\n",
    "        print(prefix + step[0])\n",
    "        if hasattr(step[1], 'estimators') and hasattr(step[1], 'weights'):\n",
    "            pprint({'estimators': list(e[0] for e in step[1].estimators), 'weights': step[1].weights})\n",
    "            print()\n",
    "            for estimator in step[1].estimators:\n",
    "                print_model(estimator[1], estimator[0]+ ' - ')\n",
    "        elif hasattr(step[1], '_base_learners') and hasattr(step[1], '_meta_learner'):\n",
    "            print(\"\\nMeta Learner\")\n",
    "            pprint(step[1]._meta_learner)\n",
    "            print()\n",
    "            for estimator in step[1]._base_learners:\n",
    "                print_model(estimator[1], estimator[0]+ ' - ')\n",
    "        else:\n",
    "            pprint(step[1].get_params())\n",
    "            print()\n",
    "            \n",
    "print_model(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8567335243553008\n",
      "0.8282442748091603\n"
     ]
    }
   ],
   "source": [
    "# テストデータの性能\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_train, fitted_model.predict(x_train_transformed)))\n",
    "print(accuracy_score(y_test, fitted_model.predict(transformations.transform(x_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./automated_best_model.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの保存\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "filename = './automated_best_model.pkl'\n",
    "joblib.dump(fitted_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\niteration = 8\\niter_run, iter_model = my_run.get_output(iteration = iteration)\\nprint(iter_run)\\nprint(\"\\n--以下モデル情報--\\n\")\\nprint_model(iter_model)\\n\\nfilename = \\'./iter_model.pkl\\'\\njoblib.dump(iter_model, filename)\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを指定して保存する場合\n",
    "'''\n",
    "iteration = 8\n",
    "iter_run, iter_model = my_run.get_output(iteration = iteration)\n",
    "print(iter_run)\n",
    "print(\"\\n--以下モデル情報--\\n\")\n",
    "print_model(iter_model)\n",
    "\n",
    "filename = './iter_model.pkl'\n",
    "joblib.dump(iter_model, filename)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解釈性・説明性技術を使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのロード\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "filename = './automated_best_model.pkl'\n",
    "#filename = './iter_model.pkl'\n",
    "\n",
    "best_model = joblib.load(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n",
       "               estimators=[('41', Pipeline(memory=None,\n",
       "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7f2a441b4358>), ('LightGBMClass...333333333333, 0.06666666666666667, 0.26666666666666666, 0.13333333333333333, 0.06666666666666667]))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルに前処理をつなげる\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline(steps=[('preprocessor', transformations),\n",
    "                        ('classifier', best_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embarked', 'sex', 'pclass', 'age', 'fare', 'sibsp', 'parch']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特徴量の名前\n",
    "feature_names = categorical_features + numeric_features\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not-Survived', 'Survived']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推論するクラスの名前\n",
    "classes =[\"not-Survived\", \"Survived\"]\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答え：生存？→ 1\n",
      "予測：生存？→ [1]\n",
      "予測：確率→ [[0.1583832 0.8416168]]\n",
      "Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked</th>\n",
       "      <th>sex</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    embarked     sex pclass  age  fare  sibsp  parch\n",
       "533        S  female      2   21 21.00      0      1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1番目のデータに着目する\n",
    "instance_num = 1\n",
    "x_test_local = x_test.iloc[instance_num:instance_num+1,:]\n",
    "print(\"答え：生存？→\", y_test[instance_num])\n",
    "print(\"予測：生存？→\", model.predict(x_test.iloc[instance_num:instance_num+1,:]))\n",
    "print(\"予測：確率→\", model.predict_proba(x_test.iloc[instance_num:instance_num+1,:]))\n",
    "print(\"Data\")\n",
    "x_test_local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルとデータの説明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明性のオブジェクトを作成\n",
    "from azureml.explain.model.tabular_explainer import TabularExplainer\n",
    "from azureml.contrib.explain.model.visualize import ExplanationDashboard\n",
    "\n",
    "tabular_explainer = TabularExplainer(model=model.steps[-1][1], \n",
    "                                     initialization_examples=x_train,\n",
    "                                     features=feature_names, \n",
    "                                     classes=classes,\n",
    "                                     transformations=transformations)\n",
    "\n",
    "# 【重要】\n",
    "# transformationsでone-hot変換を与えている\n",
    "# 以下、説明\n",
    "# https://docs.microsoft.com/ja-jp/python/api/azureml-explain-model/azureml.explain.model.tabularexplainer?view=azure-ml-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# グローバルの説明性を計算\n",
    "x_test = x_test.iloc[0:15, :]\n",
    "global_explanation = tabular_explainer.explain_global(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答え：生存？→ 1\n",
      "予測：生存？→ [1]\n",
      "予測：確率→ [[0.1583832 0.8416168]]\n",
      "Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked</th>\n",
       "      <th>sex</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    embarked     sex pclass  age  fare  sibsp  parch\n",
       "533        S  female      2   21 21.00      0      1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1番目のデータに着目する\n",
    "instance_num = 1\n",
    "x_test_local = x_test.iloc[instance_num:instance_num+1,:]\n",
    "print(\"答え：生存？→\", y_test[instance_num])\n",
    "print(\"予測：生存？→\", model.predict(x_test.iloc[instance_num:instance_num+1,:]))\n",
    "print(\"予測：確率→\", model.predict_proba(x_test.iloc[instance_num:instance_num+1,:]))\n",
    "print(\"Data\")\n",
    "x_test_local\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルとデータの説明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491f01a94b7542b1a023eab81d749e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExplanationWidget(value={'localExplanations': [[[0.006007390069643202, 0.05175036604097401, 0.0459983068783129…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<azureml.contrib.explain.model.visualize.ExplanationDashboard.ExplanationDashboard at 0x7f2a2c6cb908>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.contrib.explain.model.visualize import ExplanationDashboard\n",
    "ExplanationDashboard(global_explanation, model, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各種説明性情報の出力方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グローバルの各種情報\n",
    "\n",
    "# Sorted SHAP values\n",
    "print('ranked global importance values: {}'.format(global_explanation.get_ranked_global_values()))\n",
    "# Corresponding feature names\n",
    "print('ranked global importance names: {}'.format(global_explanation.get_ranked_global_names()))\n",
    "# feature ranks (based on original order of features)\n",
    "print('global importance rank: {}'.format(global_explanation.global_importance_rank))\n",
    "# per class feature names\n",
    "print('ranked per class feature names: {}'.format(global_explanation.get_ranked_per_class_names()))\n",
    "# per class feature importance values\n",
    "print('ranked per class feature values: {}'.format(global_explanation.get_ranked_per_class_values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globalの各種importance\n",
    "dict(zip(global_explanation.get_ranked_global_names(), global_explanation.get_ranked_global_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカルの各種情報\n",
    "instance_num = 1  # 1番目のデータの人の情報\n",
    "local_explanation = tabular_explainer.explain_local(x_test.iloc[instance_num:instance_num+1,:])\n",
    "\n",
    "prediction_value = model.predict(x_test)[instance_num]\n",
    "\n",
    "sorted_local_importance_values = local_explanation.get_ranked_local_values()[prediction_value]\n",
    "sorted_local_importance_names = local_explanation.get_ranked_local_names()[prediction_value]\n",
    "\n",
    "prediction_value,dict(zip(sorted_local_importance_names[0], sorted_local_importance_values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "mesameki"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
